# --- 1. Imports ---
import pandas as pd
from sqlalchemy import create_engine
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import networkx as nx
import matplotlib.pyplot as plt

# --- 2. Connect to Postgres ---
DB_URL = "postgresql://postgres:postgres@localhost:5432/info"
engine = create_engine(DB_URL)

# --- 3. Load sample events ---
df = pd.read_sql("SELECT id, source, content, ts FROM events LIMIT 100;", engine)
df.head()

# --- 4. Vectorize text for deduplication ---
vectorizer = TfidfVectorizer(stop_words="english")
X = vectorizer.fit_transform(df["content"].fillna(""))

# --- 5. Compute similarities ---
cosine_sim = cosine_similarity(X, X)

# --- 6. Duplicate detection ---
threshold = 0.8
edges = []
for i in range(len(df)):
    for j in range(i + 1, len(df)):
        if cosine_sim[i, j] > threshold:
            edges.append((df.iloc[i]["id"], df.iloc[j]["id"], cosine_sim[i, j]))

print(f"Found {len(edges)} duplicate pairs")

# --- 7. Build graph ---
G = nx.Graph()
for id_ in df["id"]:
    G.add_node(id_, label=str(id_))

for src, dst, weight in edges:
    G.add_edge(src, dst, weight=weight)

# --- 8. Visualize clusters ---
plt.figure(figsize=(10, 8))
pos = nx.spring_layout(G, seed=42, k=0.5)

nx.draw_networkx_nodes(G, pos, node_size=300, node_color="skyblue")
nx.draw_networkx_edges(G, pos, alpha=0.5)
nx.draw_networkx_labels(G, pos, font_size=8)

plt.title("Duplicate Event Clusters (threshold=0.8)")
plt.axis("off")
plt.show()
